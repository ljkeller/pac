{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9510a3df",
   "metadata": {},
   "source": [
    "# This file will prototype job processing for scheduling and utilization of hw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93ce4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import numexpr as ne\n",
    "import torch\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a775a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_path = Path('./jobs')\n",
    "\n",
    "def get_jobs(jobs_path):\n",
    "    # Jobs starting with _ are ignored, like the default job\n",
    "    return [f for f in jobs_path.iterdir() if f.is_file() and not f.name.startswith('_')]\n",
    "\n",
    "jobs = get_jobs(jobs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32813ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1 job to process\n"
     ]
    }
   ],
   "source": [
    "if len(jobs) == 1:\n",
    "    print('There is {} job to process'.format(len(jobs)))\n",
    "else:\n",
    "    print('There are {} jobs to process'.format(len(jobs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a50db1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNN(torch.nn.Module):\n",
    "    def __init__(self, name, sequential_arch):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.model = torch.nn.Sequential(*sequential_arch)\n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61186e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_expression(value):\n",
    "    try: \n",
    "        if isinstance(value, str) and any(op in value for op in ['+', '-', '*', '/']):\n",
    "            return ne.evaluate(value).item()\n",
    "        else:\n",
    "            return value\n",
    "    except Exception as e:\n",
    "        raise ValueError('Failed to evaluate expression {}. {}'.format(value, e))\n",
    "\n",
    "class TrainingJob():\n",
    "    def __init__(self, job_path):\n",
    "        self.path = job_path\n",
    "        self.job = None\n",
    "        self.start_time = 0.\n",
    "        self.layers = []\n",
    "    \n",
    "    def train(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_new_model(self):\n",
    "        return CustomNN(self.model_name, self.layers)\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "        with open(self.path, 'r') as f:\n",
    "            self.job = yaml.load(f, yaml.FullLoader)\n",
    "            \n",
    "        self._validate_job()\n",
    "        self.__inject()\n",
    "        \n",
    "        return self\n",
    "            \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.end_time = time.time()\n",
    "        \n",
    "        # todo: save job data: logs, pictures, model, etc... in completed dir.\n",
    "        print('Job duration: {:.2f} seconds'.format(self.end_time-self.start_time))\n",
    "\n",
    "#         if exc_type is not None:\n",
    "#             self._failure_processing()\n",
    "#         else:\n",
    "#             self._success_processing()\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def _validate_job(self):\n",
    "        '''\n",
    "        Perform minimal/basic job validation by checking YAML configuration for inconsistencies.\n",
    "        '''\n",
    "        assert 'model' in self.job\n",
    "        assert 'name' in self.job['model']\n",
    "        assert 'architecture' in self.job['model']\n",
    "        \n",
    "        assert 'ml_parameters' in self.job\n",
    "        assert 'audio_parameters' in self.job\n",
    "        assert 'job_parameters' in self.job\n",
    "        \n",
    "    def __inject(self):\n",
    "        '''Injects dependencies. Assumes inputs are validated / healthy'''\n",
    "        self.model_name = self.job['model']['name']\n",
    "        \n",
    "        for layer in self.job['model']['architecture']:\n",
    "            cls = getattr(torch.nn, layer['layer_type'])\n",
    "            layer_params = {key: evaluate_expression(value) for key, value in layer.items() if key != 'layer_type'}\n",
    "            self.layers.append(cls(**layer_params))\n",
    "        \n",
    "        for key, value in self.job['ml_parameters'].items():\n",
    "            setattr(self, key, value)\n",
    "        for key, value in self.job['audio_parameters'].items():\n",
    "            setattr(self, key, value)\n",
    "        for key, value in self.job['job_parameters'].items():\n",
    "            setattr(self, key, value)\n",
    "        \n",
    "        # Overrides for non-numeric / non-str types\n",
    "        if getattr(self, 'loss_fn'):\n",
    "            self.loss_fn = getattr(torch.nn, self.loss_fn)\n",
    "        if getattr(self, 'device'):\n",
    "            self.device = torch.device(self.device)\n",
    "        if getattr(self, 'data_path'):\n",
    "            self.data_path = Path(self.data_path).expanduser()\n",
    "        \n",
    "    def _failure_processing(self):\n",
    "        raise notImplementedError\n",
    "    def _success_processing(self):\n",
    "        raise notImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c95b532c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: sample_cnn_1.yaml\n",
      "CustomNN(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(2, 60, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(60, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): ReLU()\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Dropout(p=0.5, inplace=False)\n",
      "    (10): Linear(in_features=57600, out_features=256, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Dropout(p=0.5, inplace=False)\n",
      "    (13): Linear(in_features=256, out_features=10, bias=True)\n",
      "    (14): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "Job duration: 0.10 seconds\n"
     ]
    }
   ],
   "source": [
    "for job_path in jobs:\n",
    "    with TrainingJob(job_path) as job:\n",
    "        print('Processing: {}'.format(job.path.name))\n",
    "        model = job.get_new_model()\n",
    "        print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e911077c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9996c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
